{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8Ouz4O7Pg4Ss"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoZpLrN4hAfI",
        "outputId": "d1854aa5-b5e5-4812-9452-a984cd40f34d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "q6nfDRJMhHF8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BTRtHYd0hLB6",
        "outputId": "14807589-dbad-45c3-93f9-d3ee4820d5ff"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)),\n",
              " (array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         ...,\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]],\n",
              "  \n",
              "         [[0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          ...,\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0],\n",
              "          [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              "  array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "h5fIIa0HjA_p"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(data))\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3UI7MRTjoZH",
        "outputId": "7b752f42-ceec-4efe-8f16-d39417000e0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeto751Kjvl0",
        "outputId": "3c3923e8-7717-45ce-8b77-2379523507aa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]],\n",
              " \n",
              "        [[0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0],\n",
              "         [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8),\n",
              " array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=data[0]\n",
        "test_data=data[1]\n",
        "\n",
        "print(type(train_data))\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHGv0kqOj2VG",
        "outputId": "498a269f-904c-4833-f240-cc77da059d42"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tuple'>\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train_data[0]\n",
        "y_train=train_data[1]\n",
        "x_test=test_data[0]\n",
        "y_test=test_data[1]"
      ],
      "metadata": {
        "id": "-G3q37CQkq_v"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGYDlAkblOpB",
        "outputId": "8123c29b-661f-4959-bf67-569b4c4c6bcb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX,trainY),(testX,testY)=tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "5SZKXzX8lYiG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V7L07fclkU2",
        "outputId": "8560dfbd-a4a5-456b-87e9-0d40543e2b21"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testX.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNyFZbKPl99K",
        "outputId": "b9f30c9b-2044-499b-eb64-806d05f6bd12"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY.shape)\n",
        "print('the first 5 examples',trainY[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovnvinkel_fJ",
        "outputId": "f66ac912-6708-4450-d817-7d3c0f478a93"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000,)\n",
            "the first 5 examples [5 0 4 1 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ut_ezO-_mFKz",
        "outputId": "71440729-d4c8-4d91-a637-1a8a44309f77"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(13,13))\n",
        "for i in range(21):\n",
        "    plt.subplot(7,3,i+1)\n",
        "    plt.imshow(trainX[i],cmap='gray')\n",
        "    plt.title(f'Label:{trainY[i]}')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZBmCeRuMmJ5j",
        "outputId": "663841c9-c81f-41e7-a14f-c8aa3b2e05e2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x1300 with 21 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CGeBVx98spCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainY=tf.keras.utils.to_categorical(trainY,num_classes=10)\n",
        "testY=tf.keras.utils.to_categorical(testY,num_classes=10)"
      ],
      "metadata": {
        "id": "rr8oQhFqo5Pm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY.shape)\n",
        "print('The first 5 examples',trainY[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCxGg7GpsdRy",
        "outputId": "1ebdcc66-76ef-4ab8-cf4e-cc9887e1c74f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n",
            "The first 5 examples [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testY.shape)\n",
        "print('The first 5 examples',testY[0:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXL6AY_s7Es",
        "outputId": "ca5bea5d-55dc-4e78-cfe3-90a809571d1c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 10)\n",
            "The first 5 examples [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Sequential Model\n",
        "model=tf.keras.models.Sequential()\n",
        "\n",
        "#Restarting data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28)))\n",
        "\n",
        "#Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "#Add dense layer which provides 10 outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "# Scaling is done before machine learning\n",
        "# In deep learning scaling(Normalization) is done before compiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxLKQPcNttVl",
        "outputId": "92c30dfb-daa1-499d-a4dd-3887f3e1af61"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Comile the model\n",
        "model.compile(optimizer='sgd',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JOIO1aIbv3To"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX,trainY,batch_size=trainX.shape[0],epochs=50,validation_data=(testX,testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neIeJbeXwUzC",
        "outputId": "3ff5f924-d250-40c8-9815-9ed843118704"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.1027 - loss: 2.9234 - val_accuracy: 0.1271 - val_loss: 18.4594\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1167 - loss: 2.8276 - val_accuracy: 0.1404 - val_loss: 12.6052\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1333 - loss: 2.7360 - val_accuracy: 0.1574 - val_loss: 9.8917\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1521 - loss: 2.6485 - val_accuracy: 0.1734 - val_loss: 8.2364\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1716 - loss: 2.5652 - val_accuracy: 0.1920 - val_loss: 7.0964\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.1943 - loss: 2.4860 - val_accuracy: 0.2108 - val_loss: 6.2553\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.2167 - loss: 2.4108 - val_accuracy: 0.2302 - val_loss: 5.6060\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.2387 - loss: 2.3395 - val_accuracy: 0.2468 - val_loss: 5.0879\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.2610 - loss: 2.2720 - val_accuracy: 0.2630 - val_loss: 4.6636\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.2812 - loss: 2.2080 - val_accuracy: 0.2780 - val_loss: 4.3085\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3002 - loss: 2.1474 - val_accuracy: 0.2905 - val_loss: 4.0063\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3182 - loss: 2.0900 - val_accuracy: 0.3046 - val_loss: 3.7454\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3369 - loss: 2.0356 - val_accuracy: 0.3171 - val_loss: 3.5173\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3534 - loss: 1.9840 - val_accuracy: 0.3292 - val_loss: 3.3162\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.3704 - loss: 1.9351 - val_accuracy: 0.3398 - val_loss: 3.1373\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.3865 - loss: 1.8886 - val_accuracy: 0.3528 - val_loss: 2.9770\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4030 - loss: 1.8445 - val_accuracy: 0.3623 - val_loss: 2.8327\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4181 - loss: 1.8026 - val_accuracy: 0.3743 - val_loss: 2.7019\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4325 - loss: 1.7627 - val_accuracy: 0.3863 - val_loss: 2.5830\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.4474 - loss: 1.7248 - val_accuracy: 0.3971 - val_loss: 2.4745\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4607 - loss: 1.6886 - val_accuracy: 0.4071 - val_loss: 2.3750\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4747 - loss: 1.6542 - val_accuracy: 0.4163 - val_loss: 2.2835\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4882 - loss: 1.6213 - val_accuracy: 0.4266 - val_loss: 2.1993\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5004 - loss: 1.5900 - val_accuracy: 0.4377 - val_loss: 2.1213\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5121 - loss: 1.5601 - val_accuracy: 0.4495 - val_loss: 2.0491\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5236 - loss: 1.5316 - val_accuracy: 0.4602 - val_loss: 1.9821\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5343 - loss: 1.5043 - val_accuracy: 0.4690 - val_loss: 1.9197\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5450 - loss: 1.4782 - val_accuracy: 0.4787 - val_loss: 1.8615\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5545 - loss: 1.4532 - val_accuracy: 0.4875 - val_loss: 1.8072\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5636 - loss: 1.4293 - val_accuracy: 0.4976 - val_loss: 1.7563\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5721 - loss: 1.4064 - val_accuracy: 0.5064 - val_loss: 1.7086\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5802 - loss: 1.3844 - val_accuracy: 0.5144 - val_loss: 1.6638\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5889 - loss: 1.3633 - val_accuracy: 0.5236 - val_loss: 1.6216\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5968 - loss: 1.3431 - val_accuracy: 0.5307 - val_loss: 1.5819\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6041 - loss: 1.3237 - val_accuracy: 0.5401 - val_loss: 1.5444\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6115 - loss: 1.3050 - val_accuracy: 0.5473 - val_loss: 1.5090\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6184 - loss: 1.2870 - val_accuracy: 0.5552 - val_loss: 1.4755\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6260 - loss: 1.2698 - val_accuracy: 0.5622 - val_loss: 1.4438\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6319 - loss: 1.2531 - val_accuracy: 0.5672 - val_loss: 1.4137\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6377 - loss: 1.2371 - val_accuracy: 0.5729 - val_loss: 1.3851\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6438 - loss: 1.2216 - val_accuracy: 0.5801 - val_loss: 1.3580\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6493 - loss: 1.2067 - val_accuracy: 0.5864 - val_loss: 1.3321\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6543 - loss: 1.1923 - val_accuracy: 0.5915 - val_loss: 1.3075\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6594 - loss: 1.1785 - val_accuracy: 0.5951 - val_loss: 1.2840\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6642 - loss: 1.1650 - val_accuracy: 0.6005 - val_loss: 1.2616\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6687 - loss: 1.1521 - val_accuracy: 0.6060 - val_loss: 1.2402\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6727 - loss: 1.1395 - val_accuracy: 0.6114 - val_loss: 1.2197\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.6765 - loss: 1.1274 - val_accuracy: 0.6167 - val_loss: 1.2001\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6807 - loss: 1.1156 - val_accuracy: 0.6224 - val_loss: 1.1813\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6847 - loss: 1.1042 - val_accuracy: 0.6272 - val_loss: 1.1634\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d59e42558b0>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(testX)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJL6YuU_F9ju",
        "outputId": "8d122507-0784-4599-ff9e-d4e345ce790a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.2105417e-03, 5.7509006e-04, 1.5752908e-03, ..., 8.3743250e-01,\n",
              "        1.6071811e-02, 5.5746578e-02],\n",
              "       [3.8741229e-03, 2.5906411e-06, 7.9590005e-01, ..., 1.2357130e-08,\n",
              "        2.6299465e-02, 1.5238835e-04],\n",
              "       [3.1221344e-03, 8.3851796e-01, 2.4933249e-02, ..., 2.5004340e-02,\n",
              "        5.3785089e-02, 6.1049690e-03],\n",
              "       ...,\n",
              "       [9.4890717e-04, 8.1945785e-05, 3.4173788e-04, ..., 1.2540402e-02,\n",
              "        8.9764977e-01, 4.7798418e-02],\n",
              "       [9.5013302e-06, 1.7491687e-02, 1.2344766e-03, ..., 1.2166928e-03,\n",
              "        6.6680747e-01, 4.7173481e-02],\n",
              "       [1.3567959e-02, 1.2195101e-06, 4.7845830e-04, ..., 4.5275783e-06,\n",
              "        2.0001205e-03, 2.9633068e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGvrBMcZxN8Y",
        "outputId": "c058ccca-f0f5-4455-ac90-8383ff34c26e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6184 - loss: 1.1876\n",
            "Test Loss:1.1633541584014893\n",
            "Test Accuracy:0.6272000074386597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "VmcH7ApuHzKn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX,trainY,batch_size=trainX.shape[0],epochs=150,validation_data=(testX,testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVPuw0J4JETY",
        "outputId": "802e104c-16dc-4931-990c-f4c693e5d321"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7875 - loss: 0.7839 - val_accuracy: 0.7842 - val_loss: 0.7358\n",
            "Epoch 2/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.7886 - loss: 0.7804 - val_accuracy: 0.7855 - val_loss: 0.7319\n",
            "Epoch 3/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7895 - loss: 0.7769 - val_accuracy: 0.7874 - val_loss: 0.7282\n",
            "Epoch 4/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7904 - loss: 0.7735 - val_accuracy: 0.7890 - val_loss: 0.7245\n",
            "Epoch 5/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7916 - loss: 0.7701 - val_accuracy: 0.7898 - val_loss: 0.7209\n",
            "Epoch 6/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7924 - loss: 0.7668 - val_accuracy: 0.7909 - val_loss: 0.7174\n",
            "Epoch 7/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7934 - loss: 0.7636 - val_accuracy: 0.7920 - val_loss: 0.7140\n",
            "Epoch 8/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7944 - loss: 0.7603 - val_accuracy: 0.7933 - val_loss: 0.7106\n",
            "Epoch 9/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7955 - loss: 0.7572 - val_accuracy: 0.7946 - val_loss: 0.7073\n",
            "Epoch 10/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7964 - loss: 0.7541 - val_accuracy: 0.7960 - val_loss: 0.7041\n",
            "Epoch 11/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7972 - loss: 0.7510 - val_accuracy: 0.7981 - val_loss: 0.7010\n",
            "Epoch 12/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.7981 - loss: 0.7480 - val_accuracy: 0.7991 - val_loss: 0.6979\n",
            "Epoch 13/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.7993 - loss: 0.7450 - val_accuracy: 0.8007 - val_loss: 0.6948\n",
            "Epoch 14/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8001 - loss: 0.7421 - val_accuracy: 0.8022 - val_loss: 0.6918\n",
            "Epoch 15/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8007 - loss: 0.7392 - val_accuracy: 0.8034 - val_loss: 0.6889\n",
            "Epoch 16/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8014 - loss: 0.7364 - val_accuracy: 0.8045 - val_loss: 0.6861\n",
            "Epoch 17/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8021 - loss: 0.7336 - val_accuracy: 0.8054 - val_loss: 0.6832\n",
            "Epoch 18/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8031 - loss: 0.7309 - val_accuracy: 0.8063 - val_loss: 0.6805\n",
            "Epoch 19/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8038 - loss: 0.7281 - val_accuracy: 0.8074 - val_loss: 0.6778\n",
            "Epoch 20/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8046 - loss: 0.7255 - val_accuracy: 0.8077 - val_loss: 0.6751\n",
            "Epoch 21/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8054 - loss: 0.7228 - val_accuracy: 0.8085 - val_loss: 0.6725\n",
            "Epoch 22/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8062 - loss: 0.7202 - val_accuracy: 0.8095 - val_loss: 0.6700\n",
            "Epoch 23/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8069 - loss: 0.7176 - val_accuracy: 0.8100 - val_loss: 0.6674\n",
            "Epoch 24/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8077 - loss: 0.7151 - val_accuracy: 0.8110 - val_loss: 0.6650\n",
            "Epoch 25/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8083 - loss: 0.7126 - val_accuracy: 0.8123 - val_loss: 0.6625\n",
            "Epoch 26/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8090 - loss: 0.7101 - val_accuracy: 0.8129 - val_loss: 0.6602\n",
            "Epoch 27/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8097 - loss: 0.7077 - val_accuracy: 0.8135 - val_loss: 0.6578\n",
            "Epoch 28/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8105 - loss: 0.7053 - val_accuracy: 0.8144 - val_loss: 0.6555\n",
            "Epoch 29/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8111 - loss: 0.7029 - val_accuracy: 0.8152 - val_loss: 0.6533\n",
            "Epoch 30/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8117 - loss: 0.7006 - val_accuracy: 0.8160 - val_loss: 0.6510\n",
            "Epoch 31/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8125 - loss: 0.6983 - val_accuracy: 0.8171 - val_loss: 0.6489\n",
            "Epoch 32/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8130 - loss: 0.6960 - val_accuracy: 0.8180 - val_loss: 0.6467\n",
            "Epoch 33/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8137 - loss: 0.6938 - val_accuracy: 0.8186 - val_loss: 0.6446\n",
            "Epoch 34/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8144 - loss: 0.6915 - val_accuracy: 0.8191 - val_loss: 0.6425\n",
            "Epoch 35/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8149 - loss: 0.6894 - val_accuracy: 0.8199 - val_loss: 0.6405\n",
            "Epoch 36/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8156 - loss: 0.6872 - val_accuracy: 0.8210 - val_loss: 0.6385\n",
            "Epoch 37/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8161 - loss: 0.6850 - val_accuracy: 0.8215 - val_loss: 0.6365\n",
            "Epoch 38/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8166 - loss: 0.6829 - val_accuracy: 0.8223 - val_loss: 0.6345\n",
            "Epoch 39/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8173 - loss: 0.6808 - val_accuracy: 0.8228 - val_loss: 0.6326\n",
            "Epoch 40/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8177 - loss: 0.6788 - val_accuracy: 0.8231 - val_loss: 0.6307\n",
            "Epoch 41/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8184 - loss: 0.6768 - val_accuracy: 0.8234 - val_loss: 0.6289\n",
            "Epoch 42/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8189 - loss: 0.6747 - val_accuracy: 0.8241 - val_loss: 0.6270\n",
            "Epoch 43/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8195 - loss: 0.6728 - val_accuracy: 0.8245 - val_loss: 0.6252\n",
            "Epoch 44/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8199 - loss: 0.6708 - val_accuracy: 0.8255 - val_loss: 0.6234\n",
            "Epoch 45/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8204 - loss: 0.6688 - val_accuracy: 0.8262 - val_loss: 0.6217\n",
            "Epoch 46/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8208 - loss: 0.6669 - val_accuracy: 0.8268 - val_loss: 0.6200\n",
            "Epoch 47/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8212 - loss: 0.6650 - val_accuracy: 0.8272 - val_loss: 0.6183\n",
            "Epoch 48/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8217 - loss: 0.6632 - val_accuracy: 0.8282 - val_loss: 0.6166\n",
            "Epoch 49/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8222 - loss: 0.6613 - val_accuracy: 0.8288 - val_loss: 0.6149\n",
            "Epoch 50/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8226 - loss: 0.6595 - val_accuracy: 0.8291 - val_loss: 0.6133\n",
            "Epoch 51/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8230 - loss: 0.6577 - val_accuracy: 0.8303 - val_loss: 0.6117\n",
            "Epoch 52/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8236 - loss: 0.6559 - val_accuracy: 0.8312 - val_loss: 0.6101\n",
            "Epoch 53/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8240 - loss: 0.6541 - val_accuracy: 0.8320 - val_loss: 0.6086\n",
            "Epoch 54/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8245 - loss: 0.6523 - val_accuracy: 0.8326 - val_loss: 0.6070\n",
            "Epoch 55/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8249 - loss: 0.6506 - val_accuracy: 0.8332 - val_loss: 0.6055\n",
            "Epoch 56/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8253 - loss: 0.6489 - val_accuracy: 0.8334 - val_loss: 0.6040\n",
            "Epoch 57/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8258 - loss: 0.6472 - val_accuracy: 0.8342 - val_loss: 0.6025\n",
            "Epoch 58/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8261 - loss: 0.6455 - val_accuracy: 0.8345 - val_loss: 0.6011\n",
            "Epoch 59/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8266 - loss: 0.6439 - val_accuracy: 0.8352 - val_loss: 0.5997\n",
            "Epoch 60/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8271 - loss: 0.6422 - val_accuracy: 0.8359 - val_loss: 0.5982\n",
            "Epoch 61/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8275 - loss: 0.6406 - val_accuracy: 0.8360 - val_loss: 0.5968\n",
            "Epoch 62/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8280 - loss: 0.6390 - val_accuracy: 0.8364 - val_loss: 0.5955\n",
            "Epoch 63/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8283 - loss: 0.6374 - val_accuracy: 0.8375 - val_loss: 0.5941\n",
            "Epoch 64/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8287 - loss: 0.6358 - val_accuracy: 0.8382 - val_loss: 0.5927\n",
            "Epoch 65/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8290 - loss: 0.6343 - val_accuracy: 0.8385 - val_loss: 0.5914\n",
            "Epoch 66/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8294 - loss: 0.6327 - val_accuracy: 0.8396 - val_loss: 0.5901\n",
            "Epoch 67/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8299 - loss: 0.6312 - val_accuracy: 0.8405 - val_loss: 0.5888\n",
            "Epoch 68/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8303 - loss: 0.6297 - val_accuracy: 0.8407 - val_loss: 0.5875\n",
            "Epoch 69/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8308 - loss: 0.6282 - val_accuracy: 0.8414 - val_loss: 0.5863\n",
            "Epoch 70/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8311 - loss: 0.6267 - val_accuracy: 0.8417 - val_loss: 0.5850\n",
            "Epoch 71/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8315 - loss: 0.6252 - val_accuracy: 0.8417 - val_loss: 0.5838\n",
            "Epoch 72/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8319 - loss: 0.6238 - val_accuracy: 0.8417 - val_loss: 0.5825\n",
            "Epoch 73/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8324 - loss: 0.6223 - val_accuracy: 0.8424 - val_loss: 0.5813\n",
            "Epoch 74/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8326 - loss: 0.6209 - val_accuracy: 0.8430 - val_loss: 0.5801\n",
            "Epoch 75/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8329 - loss: 0.6195 - val_accuracy: 0.8434 - val_loss: 0.5790\n",
            "Epoch 76/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8332 - loss: 0.6181 - val_accuracy: 0.8439 - val_loss: 0.5778\n",
            "Epoch 77/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8336 - loss: 0.6167 - val_accuracy: 0.8442 - val_loss: 0.5766\n",
            "Epoch 78/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8340 - loss: 0.6154 - val_accuracy: 0.8448 - val_loss: 0.5755\n",
            "Epoch 79/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8342 - loss: 0.6140 - val_accuracy: 0.8454 - val_loss: 0.5744\n",
            "Epoch 80/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8345 - loss: 0.6127 - val_accuracy: 0.8456 - val_loss: 0.5733\n",
            "Epoch 81/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8348 - loss: 0.6113 - val_accuracy: 0.8458 - val_loss: 0.5722\n",
            "Epoch 82/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8352 - loss: 0.6100 - val_accuracy: 0.8462 - val_loss: 0.5711\n",
            "Epoch 83/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8355 - loss: 0.6087 - val_accuracy: 0.8463 - val_loss: 0.5700\n",
            "Epoch 84/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8360 - loss: 0.6074 - val_accuracy: 0.8468 - val_loss: 0.5689\n",
            "Epoch 85/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8365 - loss: 0.6061 - val_accuracy: 0.8472 - val_loss: 0.5679\n",
            "Epoch 86/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8368 - loss: 0.6048 - val_accuracy: 0.8478 - val_loss: 0.5668\n",
            "Epoch 87/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8371 - loss: 0.6036 - val_accuracy: 0.8482 - val_loss: 0.5658\n",
            "Epoch 88/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8375 - loss: 0.6023 - val_accuracy: 0.8487 - val_loss: 0.5648\n",
            "Epoch 89/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8378 - loss: 0.6011 - val_accuracy: 0.8491 - val_loss: 0.5638\n",
            "Epoch 90/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8382 - loss: 0.5999 - val_accuracy: 0.8495 - val_loss: 0.5628\n",
            "Epoch 91/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8386 - loss: 0.5987 - val_accuracy: 0.8498 - val_loss: 0.5618\n",
            "Epoch 92/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8390 - loss: 0.5975 - val_accuracy: 0.8504 - val_loss: 0.5608\n",
            "Epoch 93/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8395 - loss: 0.5963 - val_accuracy: 0.8507 - val_loss: 0.5598\n",
            "Epoch 94/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8396 - loss: 0.5951 - val_accuracy: 0.8513 - val_loss: 0.5588\n",
            "Epoch 95/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8399 - loss: 0.5939 - val_accuracy: 0.8516 - val_loss: 0.5579\n",
            "Epoch 96/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8402 - loss: 0.5927 - val_accuracy: 0.8518 - val_loss: 0.5570\n",
            "Epoch 97/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8404 - loss: 0.5916 - val_accuracy: 0.8517 - val_loss: 0.5560\n",
            "Epoch 98/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8407 - loss: 0.5904 - val_accuracy: 0.8519 - val_loss: 0.5551\n",
            "Epoch 99/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8409 - loss: 0.5893 - val_accuracy: 0.8522 - val_loss: 0.5542\n",
            "Epoch 100/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8412 - loss: 0.5882 - val_accuracy: 0.8525 - val_loss: 0.5533\n",
            "Epoch 101/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8416 - loss: 0.5871 - val_accuracy: 0.8532 - val_loss: 0.5524\n",
            "Epoch 102/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8417 - loss: 0.5860 - val_accuracy: 0.8535 - val_loss: 0.5515\n",
            "Epoch 103/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8420 - loss: 0.5849 - val_accuracy: 0.8535 - val_loss: 0.5506\n",
            "Epoch 104/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8424 - loss: 0.5838 - val_accuracy: 0.8542 - val_loss: 0.5497\n",
            "Epoch 105/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8426 - loss: 0.5827 - val_accuracy: 0.8544 - val_loss: 0.5488\n",
            "Epoch 106/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8429 - loss: 0.5816 - val_accuracy: 0.8546 - val_loss: 0.5480\n",
            "Epoch 107/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8432 - loss: 0.5806 - val_accuracy: 0.8548 - val_loss: 0.5471\n",
            "Epoch 108/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8435 - loss: 0.5795 - val_accuracy: 0.8550 - val_loss: 0.5463\n",
            "Epoch 109/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8438 - loss: 0.5785 - val_accuracy: 0.8556 - val_loss: 0.5455\n",
            "Epoch 110/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8442 - loss: 0.5774 - val_accuracy: 0.8561 - val_loss: 0.5446\n",
            "Epoch 111/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8445 - loss: 0.5764 - val_accuracy: 0.8564 - val_loss: 0.5438\n",
            "Epoch 112/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8448 - loss: 0.5754 - val_accuracy: 0.8562 - val_loss: 0.5430\n",
            "Epoch 113/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8450 - loss: 0.5744 - val_accuracy: 0.8563 - val_loss: 0.5422\n",
            "Epoch 114/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8453 - loss: 0.5734 - val_accuracy: 0.8566 - val_loss: 0.5414\n",
            "Epoch 115/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8455 - loss: 0.5724 - val_accuracy: 0.8572 - val_loss: 0.5406\n",
            "Epoch 116/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8457 - loss: 0.5714 - val_accuracy: 0.8577 - val_loss: 0.5398\n",
            "Epoch 117/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8458 - loss: 0.5704 - val_accuracy: 0.8578 - val_loss: 0.5390\n",
            "Epoch 118/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8461 - loss: 0.5694 - val_accuracy: 0.8578 - val_loss: 0.5382\n",
            "Epoch 119/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8464 - loss: 0.5685 - val_accuracy: 0.8578 - val_loss: 0.5375\n",
            "Epoch 120/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8467 - loss: 0.5675 - val_accuracy: 0.8577 - val_loss: 0.5367\n",
            "Epoch 121/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8469 - loss: 0.5666 - val_accuracy: 0.8578 - val_loss: 0.5359\n",
            "Epoch 122/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8470 - loss: 0.5656 - val_accuracy: 0.8578 - val_loss: 0.5352\n",
            "Epoch 123/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8473 - loss: 0.5647 - val_accuracy: 0.8579 - val_loss: 0.5344\n",
            "Epoch 124/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8476 - loss: 0.5637 - val_accuracy: 0.8582 - val_loss: 0.5337\n",
            "Epoch 125/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8478 - loss: 0.5628 - val_accuracy: 0.8584 - val_loss: 0.5330\n",
            "Epoch 126/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8480 - loss: 0.5619 - val_accuracy: 0.8589 - val_loss: 0.5322\n",
            "Epoch 127/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8483 - loss: 0.5610 - val_accuracy: 0.8590 - val_loss: 0.5315\n",
            "Epoch 128/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8487 - loss: 0.5601 - val_accuracy: 0.8594 - val_loss: 0.5308\n",
            "Epoch 129/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8489 - loss: 0.5592 - val_accuracy: 0.8595 - val_loss: 0.5301\n",
            "Epoch 130/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8492 - loss: 0.5583 - val_accuracy: 0.8595 - val_loss: 0.5294\n",
            "Epoch 131/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8494 - loss: 0.5574 - val_accuracy: 0.8599 - val_loss: 0.5287\n",
            "Epoch 132/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8497 - loss: 0.5566 - val_accuracy: 0.8600 - val_loss: 0.5280\n",
            "Epoch 133/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8499 - loss: 0.5557 - val_accuracy: 0.8601 - val_loss: 0.5273\n",
            "Epoch 134/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8503 - loss: 0.5548 - val_accuracy: 0.8602 - val_loss: 0.5266\n",
            "Epoch 135/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8505 - loss: 0.5540 - val_accuracy: 0.8606 - val_loss: 0.5259\n",
            "Epoch 136/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8507 - loss: 0.5531 - val_accuracy: 0.8612 - val_loss: 0.5253\n",
            "Epoch 137/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8510 - loss: 0.5523 - val_accuracy: 0.8615 - val_loss: 0.5246\n",
            "Epoch 138/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8511 - loss: 0.5514 - val_accuracy: 0.8615 - val_loss: 0.5239\n",
            "Epoch 139/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8513 - loss: 0.5506 - val_accuracy: 0.8614 - val_loss: 0.5233\n",
            "Epoch 140/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8515 - loss: 0.5498 - val_accuracy: 0.8616 - val_loss: 0.5226\n",
            "Epoch 141/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8517 - loss: 0.5489 - val_accuracy: 0.8620 - val_loss: 0.5220\n",
            "Epoch 142/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8518 - loss: 0.5481 - val_accuracy: 0.8622 - val_loss: 0.5213\n",
            "Epoch 143/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8520 - loss: 0.5473 - val_accuracy: 0.8624 - val_loss: 0.5207\n",
            "Epoch 144/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8522 - loss: 0.5465 - val_accuracy: 0.8626 - val_loss: 0.5200\n",
            "Epoch 145/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8524 - loss: 0.5457 - val_accuracy: 0.8628 - val_loss: 0.5194\n",
            "Epoch 146/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8526 - loss: 0.5449 - val_accuracy: 0.8629 - val_loss: 0.5188\n",
            "Epoch 147/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8529 - loss: 0.5441 - val_accuracy: 0.8631 - val_loss: 0.5181\n",
            "Epoch 148/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8531 - loss: 0.5433 - val_accuracy: 0.8632 - val_loss: 0.5175\n",
            "Epoch 149/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8532 - loss: 0.5426 - val_accuracy: 0.8632 - val_loss: 0.5169\n",
            "Epoch 150/150\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8534 - loss: 0.5418 - val_accuracy: 0.8633 - val_loss: 0.5163\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d59dec179b0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS9uzaDNJLZu",
        "outputId": "d6289f9f-9ae9-43ec-a6db-7a93b4bafc91"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.5669\n",
            "Test Loss:0.5162885189056396\n",
            "Test Accuracy:0.8633000254631042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "BHAtz0ZPJk3L",
        "outputId": "53029aec-f95d-4bcb-8fd5-d4d2693a74ca"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │         \u001b[38;5;34m3,136\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,598\u001b[0m (49.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,598</span> (49.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,900\u001b[0m (42.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,900</span> (42.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,696\u001b[0m (6.62 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,696</span> (6.62 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhZVG-IgLABE",
        "outputId": "e01af7a5-7683-4882-a365-c59a6da9c309"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.5669\n",
            "Test Loss:0.5162885189056396\n",
            "Test Accuracy:0.8633000254631042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX,trainY,batch_size=trainX.shape[0],epochs=50,validation_data=(testX,testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrNh82dGL_0f",
        "outputId": "911063a2-3edd-48f4-8d57-088ac0e37f64"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8535 - loss: 0.5410 - val_accuracy: 0.8634 - val_loss: 0.5157\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8537 - loss: 0.5403 - val_accuracy: 0.8635 - val_loss: 0.5151\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8540 - loss: 0.5395 - val_accuracy: 0.8638 - val_loss: 0.5145\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8542 - loss: 0.5388 - val_accuracy: 0.8639 - val_loss: 0.5139\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8544 - loss: 0.5380 - val_accuracy: 0.8642 - val_loss: 0.5133\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8546 - loss: 0.5373 - val_accuracy: 0.8641 - val_loss: 0.5127\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8548 - loss: 0.5365 - val_accuracy: 0.8641 - val_loss: 0.5121\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8551 - loss: 0.5358 - val_accuracy: 0.8643 - val_loss: 0.5115\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8553 - loss: 0.5351 - val_accuracy: 0.8648 - val_loss: 0.5109\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8555 - loss: 0.5343 - val_accuracy: 0.8649 - val_loss: 0.5104\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8557 - loss: 0.5336 - val_accuracy: 0.8654 - val_loss: 0.5098\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8559 - loss: 0.5329 - val_accuracy: 0.8657 - val_loss: 0.5092\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8561 - loss: 0.5322 - val_accuracy: 0.8658 - val_loss: 0.5087\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8564 - loss: 0.5315 - val_accuracy: 0.8659 - val_loss: 0.5081\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8565 - loss: 0.5308 - val_accuracy: 0.8663 - val_loss: 0.5075\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8567 - loss: 0.5301 - val_accuracy: 0.8666 - val_loss: 0.5070\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8569 - loss: 0.5294 - val_accuracy: 0.8667 - val_loss: 0.5064\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8572 - loss: 0.5287 - val_accuracy: 0.8668 - val_loss: 0.5059\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8574 - loss: 0.5280 - val_accuracy: 0.8668 - val_loss: 0.5053\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8576 - loss: 0.5273 - val_accuracy: 0.8671 - val_loss: 0.5048\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8577 - loss: 0.5267 - val_accuracy: 0.8672 - val_loss: 0.5043\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8578 - loss: 0.5260 - val_accuracy: 0.8676 - val_loss: 0.5037\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8579 - loss: 0.5253 - val_accuracy: 0.8676 - val_loss: 0.5032\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8582 - loss: 0.5247 - val_accuracy: 0.8677 - val_loss: 0.5027\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8585 - loss: 0.5240 - val_accuracy: 0.8678 - val_loss: 0.5021\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8587 - loss: 0.5234 - val_accuracy: 0.8678 - val_loss: 0.5016\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8588 - loss: 0.5227 - val_accuracy: 0.8680 - val_loss: 0.5011\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8590 - loss: 0.5221 - val_accuracy: 0.8680 - val_loss: 0.5006\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8593 - loss: 0.5214 - val_accuracy: 0.8682 - val_loss: 0.5001\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8594 - loss: 0.5208 - val_accuracy: 0.8682 - val_loss: 0.4995\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8596 - loss: 0.5201 - val_accuracy: 0.8681 - val_loss: 0.4990\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8598 - loss: 0.5195 - val_accuracy: 0.8684 - val_loss: 0.4985\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8600 - loss: 0.5189 - val_accuracy: 0.8685 - val_loss: 0.4980\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8601 - loss: 0.5182 - val_accuracy: 0.8685 - val_loss: 0.4975\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8602 - loss: 0.5176 - val_accuracy: 0.8686 - val_loss: 0.4970\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8604 - loss: 0.5170 - val_accuracy: 0.8687 - val_loss: 0.4965\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8606 - loss: 0.5164 - val_accuracy: 0.8688 - val_loss: 0.4960\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8607 - loss: 0.5158 - val_accuracy: 0.8690 - val_loss: 0.4955\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8608 - loss: 0.5152 - val_accuracy: 0.8690 - val_loss: 0.4951\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8610 - loss: 0.5146 - val_accuracy: 0.8693 - val_loss: 0.4946\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8613 - loss: 0.5140 - val_accuracy: 0.8696 - val_loss: 0.4941\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8614 - loss: 0.5134 - val_accuracy: 0.8698 - val_loss: 0.4936\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8615 - loss: 0.5128 - val_accuracy: 0.8699 - val_loss: 0.4931\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8616 - loss: 0.5122 - val_accuracy: 0.8701 - val_loss: 0.4927\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8617 - loss: 0.5116 - val_accuracy: 0.8702 - val_loss: 0.4922\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8618 - loss: 0.5110 - val_accuracy: 0.8704 - val_loss: 0.4917\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8619 - loss: 0.5104 - val_accuracy: 0.8704 - val_loss: 0.4912\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8620 - loss: 0.5099 - val_accuracy: 0.8706 - val_loss: 0.4908\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8622 - loss: 0.5093 - val_accuracy: 0.8706 - val_loss: 0.4903\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8624 - loss: 0.5087 - val_accuracy: 0.8707 - val_loss: 0.4899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d59df62f710>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONdrpCQ5Nhfi",
        "outputId": "6584455c-b496-473e-9eb0-6f9c7101d99a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.5401\n",
            "Test Loss:0.4898502826690674\n",
            "Test Accuracy:0.8707000017166138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX,trainY,batch_size=trainX.shape[0],epochs=100,validation_data=(testX,testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfwWmEXfPJzZ",
        "outputId": "9f716236-f2d7-47a1-9d9b-5d5863b4f081"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8625 - loss: 0.5082 - val_accuracy: 0.8709 - val_loss: 0.4894\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8626 - loss: 0.5076 - val_accuracy: 0.8710 - val_loss: 0.4889\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8628 - loss: 0.5070 - val_accuracy: 0.8712 - val_loss: 0.4885\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8630 - loss: 0.5065 - val_accuracy: 0.8713 - val_loss: 0.4880\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8632 - loss: 0.5059 - val_accuracy: 0.8715 - val_loss: 0.4876\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8633 - loss: 0.5054 - val_accuracy: 0.8716 - val_loss: 0.4871\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8634 - loss: 0.5048 - val_accuracy: 0.8717 - val_loss: 0.4867\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8635 - loss: 0.5043 - val_accuracy: 0.8718 - val_loss: 0.4862\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8636 - loss: 0.5037 - val_accuracy: 0.8719 - val_loss: 0.4858\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8636 - loss: 0.5032 - val_accuracy: 0.8720 - val_loss: 0.4854\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997ms/step - accuracy: 0.8636 - loss: 0.5026 - val_accuracy: 0.8721 - val_loss: 0.4849\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8637 - loss: 0.5021 - val_accuracy: 0.8721 - val_loss: 0.4845\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8638 - loss: 0.5016 - val_accuracy: 0.8723 - val_loss: 0.4841\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8640 - loss: 0.5010 - val_accuracy: 0.8724 - val_loss: 0.4836\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8641 - loss: 0.5005 - val_accuracy: 0.8727 - val_loss: 0.4832\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5000 - val_accuracy: 0.8727 - val_loss: 0.4828\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8645 - loss: 0.4995 - val_accuracy: 0.8725 - val_loss: 0.4823\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8646 - loss: 0.4990 - val_accuracy: 0.8726 - val_loss: 0.4819\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8648 - loss: 0.4984 - val_accuracy: 0.8727 - val_loss: 0.4815\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8648 - loss: 0.4979 - val_accuracy: 0.8729 - val_loss: 0.4811\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8650 - loss: 0.4974 - val_accuracy: 0.8730 - val_loss: 0.4807\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8651 - loss: 0.4969 - val_accuracy: 0.8730 - val_loss: 0.4802\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8651 - loss: 0.4964 - val_accuracy: 0.8730 - val_loss: 0.4798\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8653 - loss: 0.4959 - val_accuracy: 0.8732 - val_loss: 0.4794\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8655 - loss: 0.4954 - val_accuracy: 0.8733 - val_loss: 0.4790\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8655 - loss: 0.4949 - val_accuracy: 0.8733 - val_loss: 0.4786\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8656 - loss: 0.4944 - val_accuracy: 0.8733 - val_loss: 0.4782\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8658 - loss: 0.4939 - val_accuracy: 0.8735 - val_loss: 0.4778\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8658 - loss: 0.4934 - val_accuracy: 0.8735 - val_loss: 0.4774\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 992ms/step - accuracy: 0.8660 - loss: 0.4929 - val_accuracy: 0.8736 - val_loss: 0.4770\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8662 - loss: 0.4924 - val_accuracy: 0.8736 - val_loss: 0.4766\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8663 - loss: 0.4920 - val_accuracy: 0.8737 - val_loss: 0.4762\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8664 - loss: 0.4915 - val_accuracy: 0.8738 - val_loss: 0.4758\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8665 - loss: 0.4910 - val_accuracy: 0.8740 - val_loss: 0.4754\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8666 - loss: 0.4905 - val_accuracy: 0.8743 - val_loss: 0.4750\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8666 - loss: 0.4901 - val_accuracy: 0.8745 - val_loss: 0.4746\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8668 - loss: 0.4896 - val_accuracy: 0.8745 - val_loss: 0.4742\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8668 - loss: 0.4891 - val_accuracy: 0.8745 - val_loss: 0.4739\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8668 - loss: 0.4886 - val_accuracy: 0.8745 - val_loss: 0.4735\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8669 - loss: 0.4882 - val_accuracy: 0.8746 - val_loss: 0.4731\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8670 - loss: 0.4877 - val_accuracy: 0.8749 - val_loss: 0.4727\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8672 - loss: 0.4873 - val_accuracy: 0.8749 - val_loss: 0.4723\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8672 - loss: 0.4868 - val_accuracy: 0.8754 - val_loss: 0.4719\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8673 - loss: 0.4863 - val_accuracy: 0.8755 - val_loss: 0.4716\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8674 - loss: 0.4859 - val_accuracy: 0.8756 - val_loss: 0.4712\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8676 - loss: 0.4854 - val_accuracy: 0.8757 - val_loss: 0.4708\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8677 - loss: 0.4850 - val_accuracy: 0.8758 - val_loss: 0.4704\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8679 - loss: 0.4845 - val_accuracy: 0.8759 - val_loss: 0.4701\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8680 - loss: 0.4841 - val_accuracy: 0.8761 - val_loss: 0.4697\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8682 - loss: 0.4837 - val_accuracy: 0.8763 - val_loss: 0.4693\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8683 - loss: 0.4832 - val_accuracy: 0.8764 - val_loss: 0.4690\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8684 - loss: 0.4828 - val_accuracy: 0.8764 - val_loss: 0.4686\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8685 - loss: 0.4823 - val_accuracy: 0.8764 - val_loss: 0.4682\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8686 - loss: 0.4819 - val_accuracy: 0.8764 - val_loss: 0.4679\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8687 - loss: 0.4815 - val_accuracy: 0.8767 - val_loss: 0.4675\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8688 - loss: 0.4810 - val_accuracy: 0.8767 - val_loss: 0.4672\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8688 - loss: 0.4806 - val_accuracy: 0.8766 - val_loss: 0.4668\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8689 - loss: 0.4802 - val_accuracy: 0.8766 - val_loss: 0.4664\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8690 - loss: 0.4798 - val_accuracy: 0.8766 - val_loss: 0.4661\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8691 - loss: 0.4793 - val_accuracy: 0.8768 - val_loss: 0.4657\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8692 - loss: 0.4789 - val_accuracy: 0.8768 - val_loss: 0.4654\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8692 - loss: 0.4785 - val_accuracy: 0.8770 - val_loss: 0.4650\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8694 - loss: 0.4781 - val_accuracy: 0.8770 - val_loss: 0.4647\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8695 - loss: 0.4777 - val_accuracy: 0.8771 - val_loss: 0.4643\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8696 - loss: 0.4772 - val_accuracy: 0.8775 - val_loss: 0.4640\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8697 - loss: 0.4768 - val_accuracy: 0.8776 - val_loss: 0.4636\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8699 - loss: 0.4764 - val_accuracy: 0.8778 - val_loss: 0.4633\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8701 - loss: 0.4760 - val_accuracy: 0.8781 - val_loss: 0.4630\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8701 - loss: 0.4756 - val_accuracy: 0.8781 - val_loss: 0.4626\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8702 - loss: 0.4752 - val_accuracy: 0.8782 - val_loss: 0.4623\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8703 - loss: 0.4748 - val_accuracy: 0.8783 - val_loss: 0.4619\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8704 - loss: 0.4744 - val_accuracy: 0.8784 - val_loss: 0.4616\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8704 - loss: 0.4740 - val_accuracy: 0.8785 - val_loss: 0.4613\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8704 - loss: 0.4736 - val_accuracy: 0.8785 - val_loss: 0.4609\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8705 - loss: 0.4732 - val_accuracy: 0.8785 - val_loss: 0.4606\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8706 - loss: 0.4728 - val_accuracy: 0.8787 - val_loss: 0.4603\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8706 - loss: 0.4724 - val_accuracy: 0.8787 - val_loss: 0.4599\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8707 - loss: 0.4720 - val_accuracy: 0.8787 - val_loss: 0.4596\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8708 - loss: 0.4716 - val_accuracy: 0.8788 - val_loss: 0.4593\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8709 - loss: 0.4712 - val_accuracy: 0.8790 - val_loss: 0.4590\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8710 - loss: 0.4709 - val_accuracy: 0.8790 - val_loss: 0.4586\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8711 - loss: 0.4705 - val_accuracy: 0.8793 - val_loss: 0.4583\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8712 - loss: 0.4701 - val_accuracy: 0.8793 - val_loss: 0.4580\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8714 - loss: 0.4697 - val_accuracy: 0.8794 - val_loss: 0.4577\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8715 - loss: 0.4693 - val_accuracy: 0.8794 - val_loss: 0.4573\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8716 - loss: 0.4689 - val_accuracy: 0.8793 - val_loss: 0.4570\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8717 - loss: 0.4686 - val_accuracy: 0.8794 - val_loss: 0.4567\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8718 - loss: 0.4682 - val_accuracy: 0.8794 - val_loss: 0.4564\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8719 - loss: 0.4678 - val_accuracy: 0.8796 - val_loss: 0.4561\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8719 - loss: 0.4675 - val_accuracy: 0.8797 - val_loss: 0.4558\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8720 - loss: 0.4671 - val_accuracy: 0.8797 - val_loss: 0.4554\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8722 - loss: 0.4667 - val_accuracy: 0.8799 - val_loss: 0.4551\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8722 - loss: 0.4663 - val_accuracy: 0.8801 - val_loss: 0.4548\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8723 - loss: 0.4660 - val_accuracy: 0.8803 - val_loss: 0.4545\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8723 - loss: 0.4656 - val_accuracy: 0.8804 - val_loss: 0.4542\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8724 - loss: 0.4653 - val_accuracy: 0.8804 - val_loss: 0.4539\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8725 - loss: 0.4649 - val_accuracy: 0.8804 - val_loss: 0.4536\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8727 - loss: 0.4645 - val_accuracy: 0.8807 - val_loss: 0.4533\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8727 - loss: 0.4642 - val_accuracy: 0.8807 - val_loss: 0.4530\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8727 - loss: 0.4638 - val_accuracy: 0.8808 - val_loss: 0.4527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d59deb549b0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPp5pYyEPULa",
        "outputId": "fd5f7a94-1ae0-4a69-a25b-2c1ee8b6d8bf"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.5017\n",
            "Test Loss:0.45267754793167114\n",
            "Test Accuracy:0.8808000087738037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX,trainY,batch_size=trainX.shape[0],epochs=100,validation_data=(testX,testY))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_lyQRusQWEy",
        "outputId": "72aa6716-ab73-423d-e653-e1912d58b35f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8728 - loss: 0.4635 - val_accuracy: 0.8810 - val_loss: 0.4524\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8729 - loss: 0.4631 - val_accuracy: 0.8812 - val_loss: 0.4521\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8729 - loss: 0.4628 - val_accuracy: 0.8812 - val_loss: 0.4518\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8730 - loss: 0.4624 - val_accuracy: 0.8813 - val_loss: 0.4515\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8731 - loss: 0.4620 - val_accuracy: 0.8813 - val_loss: 0.4512\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8732 - loss: 0.4617 - val_accuracy: 0.8813 - val_loss: 0.4509\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 968ms/step - accuracy: 0.8732 - loss: 0.4614 - val_accuracy: 0.8812 - val_loss: 0.4506\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949ms/step - accuracy: 0.8733 - loss: 0.4610 - val_accuracy: 0.8813 - val_loss: 0.4503\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970ms/step - accuracy: 0.8734 - loss: 0.4607 - val_accuracy: 0.8813 - val_loss: 0.4500\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941ms/step - accuracy: 0.8735 - loss: 0.4603 - val_accuracy: 0.8813 - val_loss: 0.4497\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8737 - loss: 0.4600 - val_accuracy: 0.8813 - val_loss: 0.4494\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8737 - loss: 0.4596 - val_accuracy: 0.8813 - val_loss: 0.4491\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8738 - loss: 0.4593 - val_accuracy: 0.8814 - val_loss: 0.4488\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8739 - loss: 0.4590 - val_accuracy: 0.8817 - val_loss: 0.4485\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8740 - loss: 0.4586 - val_accuracy: 0.8818 - val_loss: 0.4483\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8741 - loss: 0.4583 - val_accuracy: 0.8818 - val_loss: 0.4480\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8742 - loss: 0.4580 - val_accuracy: 0.8818 - val_loss: 0.4477\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8743 - loss: 0.4576 - val_accuracy: 0.8819 - val_loss: 0.4474\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8744 - loss: 0.4573 - val_accuracy: 0.8819 - val_loss: 0.4471\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8744 - loss: 0.4570 - val_accuracy: 0.8820 - val_loss: 0.4468\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8745 - loss: 0.4566 - val_accuracy: 0.8820 - val_loss: 0.4466\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8746 - loss: 0.4563 - val_accuracy: 0.8820 - val_loss: 0.4463\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8746 - loss: 0.4560 - val_accuracy: 0.8821 - val_loss: 0.4460\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8747 - loss: 0.4557 - val_accuracy: 0.8822 - val_loss: 0.4457\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8749 - loss: 0.4553 - val_accuracy: 0.8823 - val_loss: 0.4454\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8750 - loss: 0.4550 - val_accuracy: 0.8823 - val_loss: 0.4452\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8752 - loss: 0.4547 - val_accuracy: 0.8823 - val_loss: 0.4449\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8753 - loss: 0.4544 - val_accuracy: 0.8822 - val_loss: 0.4446\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8753 - loss: 0.4540 - val_accuracy: 0.8823 - val_loss: 0.4443\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8754 - loss: 0.4537 - val_accuracy: 0.8824 - val_loss: 0.4441\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8755 - loss: 0.4534 - val_accuracy: 0.8825 - val_loss: 0.4438\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8755 - loss: 0.4531 - val_accuracy: 0.8825 - val_loss: 0.4435\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8756 - loss: 0.4528 - val_accuracy: 0.8827 - val_loss: 0.4432\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8757 - loss: 0.4525 - val_accuracy: 0.8828 - val_loss: 0.4430\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8757 - loss: 0.4522 - val_accuracy: 0.8828 - val_loss: 0.4427\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8758 - loss: 0.4518 - val_accuracy: 0.8829 - val_loss: 0.4424\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8758 - loss: 0.4515 - val_accuracy: 0.8832 - val_loss: 0.4422\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8759 - loss: 0.4512 - val_accuracy: 0.8832 - val_loss: 0.4419\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8760 - loss: 0.4509 - val_accuracy: 0.8832 - val_loss: 0.4416\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8761 - loss: 0.4506 - val_accuracy: 0.8832 - val_loss: 0.4414\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8762 - loss: 0.4503 - val_accuracy: 0.8832 - val_loss: 0.4411\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8763 - loss: 0.4500 - val_accuracy: 0.8832 - val_loss: 0.4409\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8763 - loss: 0.4497 - val_accuracy: 0.8832 - val_loss: 0.4406\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8764 - loss: 0.4494 - val_accuracy: 0.8832 - val_loss: 0.4403\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8764 - loss: 0.4491 - val_accuracy: 0.8831 - val_loss: 0.4401\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8765 - loss: 0.4488 - val_accuracy: 0.8833 - val_loss: 0.4398\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8765 - loss: 0.4485 - val_accuracy: 0.8834 - val_loss: 0.4396\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8766 - loss: 0.4482 - val_accuracy: 0.8834 - val_loss: 0.4393\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8766 - loss: 0.4479 - val_accuracy: 0.8836 - val_loss: 0.4390\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8767 - loss: 0.4476 - val_accuracy: 0.8836 - val_loss: 0.4388\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8767 - loss: 0.4473 - val_accuracy: 0.8836 - val_loss: 0.4385\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8769 - loss: 0.4470 - val_accuracy: 0.8837 - val_loss: 0.4383\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8769 - loss: 0.4467 - val_accuracy: 0.8837 - val_loss: 0.4380\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8770 - loss: 0.4464 - val_accuracy: 0.8837 - val_loss: 0.4378\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8770 - loss: 0.4462 - val_accuracy: 0.8838 - val_loss: 0.4375\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8771 - loss: 0.4459 - val_accuracy: 0.8838 - val_loss: 0.4373\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8772 - loss: 0.4456 - val_accuracy: 0.8838 - val_loss: 0.4370\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8772 - loss: 0.4453 - val_accuracy: 0.8839 - val_loss: 0.4368\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8772 - loss: 0.4450 - val_accuracy: 0.8840 - val_loss: 0.4365\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8773 - loss: 0.4447 - val_accuracy: 0.8840 - val_loss: 0.4363\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8773 - loss: 0.4444 - val_accuracy: 0.8840 - val_loss: 0.4360\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8773 - loss: 0.4441 - val_accuracy: 0.8840 - val_loss: 0.4358\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8774 - loss: 0.4439 - val_accuracy: 0.8841 - val_loss: 0.4355\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8775 - loss: 0.4436 - val_accuracy: 0.8840 - val_loss: 0.4353\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8776 - loss: 0.4433 - val_accuracy: 0.8841 - val_loss: 0.4351\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8777 - loss: 0.4430 - val_accuracy: 0.8844 - val_loss: 0.4348\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8777 - loss: 0.4427 - val_accuracy: 0.8844 - val_loss: 0.4346\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8777 - loss: 0.4425 - val_accuracy: 0.8843 - val_loss: 0.4343\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8778 - loss: 0.4422 - val_accuracy: 0.8843 - val_loss: 0.4341\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8779 - loss: 0.4419 - val_accuracy: 0.8843 - val_loss: 0.4338\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8779 - loss: 0.4416 - val_accuracy: 0.8844 - val_loss: 0.4336\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8780 - loss: 0.4414 - val_accuracy: 0.8845 - val_loss: 0.4334\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8781 - loss: 0.4411 - val_accuracy: 0.8845 - val_loss: 0.4331\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8781 - loss: 0.4408 - val_accuracy: 0.8845 - val_loss: 0.4329\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8781 - loss: 0.4406 - val_accuracy: 0.8845 - val_loss: 0.4327\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8782 - loss: 0.4403 - val_accuracy: 0.8845 - val_loss: 0.4324\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8783 - loss: 0.4400 - val_accuracy: 0.8846 - val_loss: 0.4322\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8783 - loss: 0.4397 - val_accuracy: 0.8846 - val_loss: 0.4320\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8783 - loss: 0.4395 - val_accuracy: 0.8846 - val_loss: 0.4317\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8784 - loss: 0.4392 - val_accuracy: 0.8847 - val_loss: 0.4315\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8784 - loss: 0.4389 - val_accuracy: 0.8848 - val_loss: 0.4313\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8785 - loss: 0.4387 - val_accuracy: 0.8850 - val_loss: 0.4310\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8786 - loss: 0.4384 - val_accuracy: 0.8850 - val_loss: 0.4308\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8786 - loss: 0.4382 - val_accuracy: 0.8852 - val_loss: 0.4306\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8786 - loss: 0.4379 - val_accuracy: 0.8853 - val_loss: 0.4303\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8787 - loss: 0.4376 - val_accuracy: 0.8852 - val_loss: 0.4301\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8788 - loss: 0.4374 - val_accuracy: 0.8854 - val_loss: 0.4299\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8788 - loss: 0.4371 - val_accuracy: 0.8854 - val_loss: 0.4297\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 973ms/step - accuracy: 0.8789 - loss: 0.4369 - val_accuracy: 0.8854 - val_loss: 0.4294\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8790 - loss: 0.4366 - val_accuracy: 0.8855 - val_loss: 0.4292\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8790 - loss: 0.4363 - val_accuracy: 0.8855 - val_loss: 0.4290\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8791 - loss: 0.4361 - val_accuracy: 0.8855 - val_loss: 0.4288\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8791 - loss: 0.4358 - val_accuracy: 0.8855 - val_loss: 0.4285\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8792 - loss: 0.4356 - val_accuracy: 0.8855 - val_loss: 0.4283\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8793 - loss: 0.4353 - val_accuracy: 0.8855 - val_loss: 0.4281\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8794 - loss: 0.4351 - val_accuracy: 0.8855 - val_loss: 0.4279\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8794 - loss: 0.4348 - val_accuracy: 0.8856 - val_loss: 0.4276\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.8795 - loss: 0.4346 - val_accuracy: 0.8856 - val_loss: 0.4274\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8796 - loss: 0.4343 - val_accuracy: 0.8855 - val_loss: 0.4272\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8796 - loss: 0.4341 - val_accuracy: 0.8857 - val_loss: 0.4270\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d59df62d0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(testX,testY)\n",
        "print(f'Test Loss:{loss}')\n",
        "print(f'Test Accuracy:{accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Pm2HV0OSymS",
        "outputId": "8578fded-67ef-4d5c-cb36-d956a7d1a201"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.4748\n",
            "Test Loss:0.4269917905330658\n",
            "Test Accuracy:0.885699987411499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DrG29YVoTcF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}